# -*- coding: utf-8 -*-
"""Uji Coba Kfold

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nnul_N37rAv_Od584RSxmV5-9qe6RXKb
"""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split #Library untuk memisahkan dataset menjadi train dan test
from sklearn.naive_bayes import CategoricalNB #Import Library untuk GaussianNaiveBayes
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score #Import Library untuk Confusion Matrix dan Accuracy (sejenis evaluasi)
from sklearn.metrics import classification_report #Import Library untuk TINGKAT_KEification Report (sejenis evaluasi)
from sklearn.metrics import roc_curve #Import Library untuk ROC Curve (sejenis evaluasi)
from sklearn.model_selection import KFold

das = pd.read_csv('/content/DATASET LENGKAP.csv')
print(das)

"""## Informasi Data"""

das.info()

#Tampilan Data 5 terakhir
das.tail(5)

"""## Cleaning Data"""

#Mengambil data yang diperlukan pada kasus ini Kabupaten Semarang yang akan diambil.
das_sem = das[das["DLM_LUAR"] == "Dalam Kawasan"]
das_sem

"""## Data Selection"""

# Membuang kolom yang tidak diperlukan, yaitu terdapat 14 kolom yang tidak akan digunakan
#['WIL_KERJA', 'KETERANGAN', 'PENUTUPAN', 'SKOR_VEG', 'SKOR_PRD', 'KEMIRINGAN', 'SKOR_LER', 'SKOR_EROSI', 'FUNGSI', 'SKOR_MNJ', 'TOTAL_SKOR', 'LUAS', 'LUAS_HA',' KELILING']
dropped_columns = ["KABUPATEN","KECAMATAN","DESA","R","K","LS","CP","A","EROSI","LERENG","PL","FUNGSI_KWS","DLM_LUAR","CP/LUAS_HA","(CP/LUAS_HA)*100", " LUAS_HA "]
das_sema = das_sem.drop(dropped_columns, axis=1)

das_sema

missing_values = das_sema.isnull().sum()
print(missing_values)

"""### Menjawab Rumusan Masalah Terkait Gambaran Umum Daerah Aliran Sungai Pemali Jratun di Kabupaten Semarang"""

#Menambahkan library untuk visualisasi data
import plotly.figure_factory as ff
import plotly.express as px

# Calculate count of each category
category_counts = das_sema['KELAS_VEG'].value_counts()

# Create pie chart
fig = px.pie(category_counts, values=category_counts.values, names=category_counts.index, title="Melihat Data Kelas Vegetasi (Penutupan Lahan)")

# Show the pie chart
fig.show()

# Calculate count of each category
category_counts = das_sema['KELAS_LERENG'].value_counts()

# Create pie chart
fig = px.pie(category_counts, values=category_counts.values, names=category_counts.index, title="Melihat Data Kelas Lereng")

# Show the pie chart
fig.show()

# Calculate count of each category
category_counts = das_sema['KELAS_EROSI'].value_counts()

# Create pie chart
fig = px.pie(category_counts, values=category_counts.values, names=category_counts.index, title="Melihat Data Kelas Tingkat Bahaya Erosi")

# Show the pie chart
fig.show()

"""## Data Transformasi"""

das_sema.loc[das_sema['KELAS_VEG'] == 'sangat baik', 'KELAS_VEG'] = 5
das_sema.loc[das_sema['KELAS_VEG'] == 'baik', 'KELAS_VEG'] = 4
das_sema.loc[das_sema['KELAS_VEG'] == 'sedang', 'KELAS_VEG'] = 3
das_sema.loc[das_sema['KELAS_VEG'] == 'buruk', 'KELAS_VEG'] = 2
das_sema.loc[das_sema['KELAS_VEG'] == 'sangat buruk', 'KELAS_VEG'] = 1

das_sema.loc[das_sema['KELAS_LERENG'] == 'datar', 'KELAS_LERENG'] = 5
das_sema.loc[das_sema['KELAS_LERENG'] == 'landai', 'KELAS_LERENG'] = 4
das_sema.loc[das_sema['KELAS_LERENG'] == 'agak curam', 'KELAS_LERENG'] = 3
das_sema.loc[das_sema['KELAS_LERENG'] == 'curam', 'KELAS_LERENG'] = 2
das_sema.loc[das_sema['KELAS_LERENG'] == 'sangat curam', 'KELAS_LERENG'] = 1


das_sema.loc[das_sema['KELAS_EROSI'] == 'sangat ringan', 'KELAS_EROSI'] = 5
das_sema.loc[das_sema['KELAS_EROSI'] == 'ringan', 'KELAS_EROSI'] = 4
das_sema.loc[das_sema['KELAS_EROSI'] == 'sedang', 'KELAS_EROSI'] = 3
das_sema.loc[das_sema['KELAS_EROSI'] == 'berat', 'KELAS_EROSI'] = 2
das_sema.loc[das_sema['KELAS_EROSI'] == 'sangat berat', 'KELAS_EROSI'] = 1

das_sema.loc[das_sema['KRITIS'] == 'Sangat Kritis', 'KRITIS'] = 5
das_sema.loc[das_sema['KRITIS'] == 'Kritis', 'KRITIS'] = 4
das_sema.loc[das_sema['KRITIS'] == 'Agak Kritis', 'KRITIS'] = 3
das_sema.loc[das_sema['KRITIS'] == 'Potensial Kritis', 'KRITIS'] = 2
das_sema.loc[das_sema['KRITIS'] == 'Tidak Kritis', 'KRITIS'] = 1

das_sema = das_sema.apply(pd.to_numeric, errors='coerce')
das_sema

"""## Data Mining (Proses Pemodelan)"""

# Variabel independen
#x = das_sema.drop(["KRITIS"], axis = 1)
#x.head()

# Variabel dependen
#y = das_sema["KRITIS"]
#y.head()

#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0)

from sklearn.model_selection import train_test_split, KFold
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
import numpy as np

# Contoh DataFrame
x = das_sema[['KELAS_VEG', 'KELAS_EROSI', 'KELAS_LERENG']] # Ganti dengan nama kolom yang sesuai
y = das_sema['KRITIS'] # Ganti dengan nama kolom yang sesuai

# Inisialisasi model GaussianNB
model = GaussianNB()

# Jumlah fold yang diinginkan
num_folds = 10

# Inisialisasi KFold
kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)

# Inisialisasi variabel untuk menyimpan akurasi tiap fold
accuracies = []

# Lakukan k-fold cross-validation
for train_index, test_index in kf.split(x):
    # Bagi data menjadi data training dan data testing menggunakan train_test_split
    x_train, x_test, y_train, y_test = train_test_split(x.iloc[train_index], y.iloc[train_index], test_size=0.30, random_state=42)

    # Latih model menggunakan data training
    model.fit(x_train, y_train)

    # Lakukan prediksi pada data testing
    y_pred = model.predict(x_test)

    # Hitung akurasi dan simpan ke dalam list accuracies
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)

    # Tampilkan hasil akurasi tiap fold
    print("Akurasi pada fold {}: {:.2f}".format(len(accuracies), accuracy))

# Hitung rata-rata akurasi dari semua fold
average_accuracy = np.mean(accuracies)
print("Rata-rata akurasi dari {}-fold cross-validation: {:.2f}".format(num_folds, average_accuracy))

from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred), "\t: is the confusion matrix")
#akurasi matriks
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred), "\t: is the accuracy score")

from sklearn.metrics import precision_score
# Menghitung precision score (multikelas)
precision_micro = precision_score(y_test, y_pred, average='micro')
precision_macro = precision_score(y_test, y_pred, average='macro')
precision_weighted = precision_score(y_test, y_pred, average='weighted')
print("Precision Score (Micro):", precision_micro)
print("Precision Score (Macro):", precision_macro)
print("Precision Score (Weighted):", precision_weighted)

from sklearn.metrics import recall_score
# Menghitung recall score (multikelas)
recall_micro = recall_score(y_test, y_pred, average='micro')
recall_macro = recall_score(y_test, y_pred, average='macro')
recall_weighted = recall_score(y_test, y_pred, average='weighted')
print("Recall Score (Micro):", recall_micro)
print("Recall Score (Macro):", recall_macro)
print("Recall Score (Weighted):", recall_weighted)


from sklearn.metrics import f1_score
# Menghitung f1 score (multikelas)
f1_micro = f1_score(y_test, y_pred, average='micro')
f1_macro = f1_score(y_test, y_pred, average='macro')
f1_weighted = f1_score(y_test, y_pred, average='weighted')
print("F1 Score (Micro):", f1_micro)
print("F1 Score (Macro):", f1_macro)
print("F1 Score (Weighted):", f1_weighted)

len(x_test)

y_pred = model.predict(x_test)
print(y_pred)

len(y_pred)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# Calculate the confusion matrix
#
conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""## Visualisasi Data"""

sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix\nAccuracy: {:.2f}'.format(accuracy))
plt.show()

plt.figure(figsize=(8, 6))
sns.countplot(x=y_pred, palette='Blues')
plt.xlabel('Predicted Class')
plt.ylabel('Count')
plt.title('Prediction Results\nAccuracy: {:.2f}'.format(accuracy))

# Tambahkan keterangan jumlah pada setiap bar
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')

plt.show()